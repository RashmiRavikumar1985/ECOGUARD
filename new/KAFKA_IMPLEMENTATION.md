# Kafka Live Stream Integration - Implementation Summary

## âœ… What Was Implemented

### 1. **Kafka WebSocket Service** (`src/services/kafkaService.ts`)
- Pure consumer service - NO calculations
- WebSocket connection to backend Kafka proxy
- Automatic reconnection with exponential backoff
- Topic subscription/unsubscription
- Message parsing and routing

### 2. **Kafka Connection Hook** (`src/hooks/useKafkaConnection.ts`)
- Manages connection lifecycle
- Provides connection status
- Auto-connect on mount
- Error handling

### 3. **Kafka Data Hooks** (Pure Consumers)

#### `useKafkaZones.ts`
- âœ… Subscribes to `risk-zones-updates` topic
- âœ… Receives pre-calculated zone data
- âœ… Updates React state (NO calculations)
- âœ… Filters zones by viewport (UI optimization only)

#### `useKafkaStats.ts`
- âœ… Subscribes to `aggregated-stats` topic
- âœ… Receives pre-calculated statistics
- âœ… Updates DensityIndexCard (NO aggregations)

#### `useKafkaTicker.ts`
- âœ… Subscribes to `system-logs` and `data-ingestion` topics
- âœ… Receives log messages from backend
- âœ… Updates LiveDataTicker (NO mock generation)

### 4. **Updated Types** (`src/types/overlays.ts`)
- âœ… Added `RiskLevel` type: "SAFE" | "WATCH" | "WARNING" | "CRITICAL"
- âœ… Updated `Zone` type with Kafka fields:
  - `riskLevel`: From ML model
  - `riskProbability`: From ML model
  - `ari`: Pre-calculated by backend
  - `slopeAngle`: From DEM processing
  - `ndvi`: From Sentinel-2 processing
- âœ… Updated `DensityStats` with zone counts from backend

### 5. **Updated Components**

#### `MapView.tsx`
- âœ… Integrated `useKafkaZones` hook
- âœ… Renders risk zones with color coding based on `riskLevel`
- âœ… Zone tooltips show risk information
- âœ… Click handlers for zone selection

#### `ZoneTooltip.tsx`
- âœ… Displays risk level and probability
- âœ… Shows ARI (if available)
- âœ… All values from Kafka (NO calculations)

#### `DensityIndexCard.tsx`
- âœ… Displays zone counts (Critical/Warning/Watch/Safe)
- âœ… All stats from Kafka (NO aggregations)

#### `GeoViewer.tsx`
- âœ… Uses Kafka hooks instead of mock hooks
- âœ… Connection status tracking
- âœ… Zone click handler

### 6. **Removed Mock Logic**

#### `zoneService.ts`
- âŒ Removed: `generateZones()` mock function
- âœ… Kept: Utility functions (filtering, bounds checking - UI only)

#### Old Hooks (Still exist but not used)
- `useZones.ts` - Replaced by `useKafkaZones`
- `useDensityStats.ts` - Replaced by `useKafkaStats`
- `useTickerLog.ts` - Replaced by `useKafkaTicker`

---

## ğŸ“‹ Kafka Topics Required (Backend)

The frontend expects these Kafka topics:

1. **`risk-zones-updates`**
   - Message format: `KafkaMessage<Zone>`
   - Contains: riskLevel, riskProbability, rainfall, soilMoisture, ari, etc.
   - Frequency: Real-time updates per zone

2. **`aggregated-stats`**
   - Message format: `KafkaMessage<DensityStats>`
   - Contains: activePoints, avgIntensity, zone counts
   - Frequency: Periodic aggregation (e.g., every 5 seconds)

3. **`system-logs`**
   - Message format: `KafkaMessage<{ message: string, level?: string }>`
   - Contains: System status messages
   - Frequency: As events occur

4. **`data-ingestion`**
   - Message format: `KafkaMessage<{ message: string, source?: string }>`
   - Contains: Data packet receipts (GPM, SMAP, etc.)
   - Frequency: As data arrives

---

## ğŸ”Œ Backend Requirements

### WebSocket Endpoint
- URL: `ws://localhost:8080/kafka` (configurable via `VITE_KAFKA_WS_URL`)
- Protocol: JSON messages over WebSocket
- Message format:
  ```json
  {
    "type": "subscribe" | "unsubscribe" | "message",
    "topic": "risk-zones-updates",
    "data": { ... }
  }
  ```

### Kafka Message Format
All messages should follow:
```typescript
{
  topic: string;
  timestamp: string; // ISO 8601
  value: T; // Your data
}
```

---

## âœ… What Frontend Does (Pure Consumer)

1. âœ… Connects to Kafka via WebSocket
2. âœ… Subscribes to topics
3. âœ… Receives messages
4. âœ… Updates React state
5. âœ… Renders UI components
6. âœ… Formats data for display
7. âœ… Handles user interactions

---

## âŒ What Frontend Does NOT Do

1. âŒ Calculate ARI
2. âŒ Classify risk levels
3. âŒ Run ML models
4. âŒ Process rainfall data
5. âŒ Aggregate statistics
6. âŒ Calculate thresholds
7. âŒ Generate mock data

**All intelligence lives in backend/Kafka producers!**

---

## ğŸš€ Next Steps

1. **Backend Setup**: Implement WebSocket server that bridges to Kafka
2. **Kafka Producers**: Create producers for each topic
3. **Testing**: Test with real Kafka messages
4. **Environment Config**: Set `VITE_KAFKA_WS_URL` in `.env`
5. **Remove Old Hooks**: Delete `useZones.ts`, `useDensityStats.ts`, `useTickerLog.ts` after verification

---

## ğŸ“ Environment Variable

Create `.env` file:
```
VITE_KAFKA_WS_URL=ws://localhost:8080/kafka
```

Or set in your deployment environment.
